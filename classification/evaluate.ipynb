{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from help_functions import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIMENSION = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'checkpoints/naive_26_labels_weights_20220531/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n",
      "   epoch  accuracy      loss  val_accuracy  val_loss\n",
      "0      0   0.21582  0.134346      0.264709  0.184852\n"
     ]
    }
   ],
   "source": [
    "training_metrics = pd.read_csv(checkpoint_dir + 'history.csv')\n",
    "print(training_metrics.shape)\n",
    "print(training_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training metrics: loss & accuracy\n",
    "\n",
    "epochs = training_metrics.shape[0]\n",
    "\n",
    "acc = training_metrics.accuracy.values\n",
    "loss = training_metrics.loss.values\n",
    "\n",
    "val_acc = training_metrics.val_accuracy.values\n",
    "val_loss = training_metrics.val_loss.values\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(epochs), acc, label='Training Accuracy')\n",
    "plt.plot(range(epochs), val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(epochs), loss, label='Training Loss')\n",
    "plt.plot(range(epochs), val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------- Test images -----------\n",
      "Found 25000 validated image filenames belonging to 24 classes.\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_json('data/splitted_dfs_500k_20220602/test_df.json.bz2', compression='bz2')\n",
    "test_generator = ImageDataGenerator() \n",
    "print('\\n----------- Test images -----------')          \n",
    "test = test_generator.flow_from_dataframe(dataframe=test_df,\n",
    "                                          directory='/scratch/WIT_Dataset/images',\n",
    "                                          x_col='url', \n",
    "                                          y_col='labels', \n",
    "                                          batch_size=32,\n",
    "                                          class_mode='categorical',\n",
    "                                          validate_filenames=True,\n",
    "                                          target_size=(IMAGE_DIMENSION, IMAGE_DIMENSION))\n",
    "N_LABELS = len(test.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and load model weights\n",
    "model = create_model(model_name='EfficientNetB0', n_labels=N_LABELS, image_dimension=IMAGE_DIMENSION)\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "print(latest)\n",
    "model.load_weights(latest)\n",
    "\n",
    "# Evaluate model\n",
    "loss, acc = model.evaluate(test, verbose=1)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "\n",
    "predictions = model.predict(test, verbose=1)\n",
    "threshold = 0.5\n",
    "y_pred = 1 * (predictions > threshold)\n",
    "y_true = np.zeros(y_pred.shape)\n",
    "for row_idx, row in enumerate(test.classes):\n",
    "    for idx in row:\n",
    "        y_true[row_idx, idx] = 1\n",
    "print(f'ROC AUC: {roc_auc_score(y_true, y_pred):.4f}')\n",
    "\n",
    "# N_CLASSES = y_true.shape[1]\n",
    "metrics_df = pd.DataFrame(classification_report(y_true, y_pred, target_names=list(test.class_indices), output_dict=True)).transpose()\n",
    "metrics_df['index'] = np.concatenate((np.arange(start=0, stop=N_CLASSES), [None, None, None, None]))\n",
    "print(metrics_df)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12,12))\n",
    "\n",
    "# Precision\n",
    "sorted_indices_precision = np.argsort(metrics_df.precision[0:N_CLASSES])\n",
    "sorted_precisions_per_class = metrics_df.precision[0:N_CLASSES][sorted_indices_precision]\n",
    "# Recall\n",
    "sorted_indices_recall = np.argsort(metrics_df.recall[0:N_CLASSES])\n",
    "sorted_recalls_per_class = metrics_df.recall[0:N_CLASSES][sorted_indices_recall]\n",
    "\n",
    "print('\\n\\n ----------- PER-CLASS ACCURACY ----------- \\n ')\n",
    "# Per-class accuracy\n",
    "from collections import Counter\n",
    "total = Counter()\n",
    "correct = Counter()\n",
    "for i in range(len(test.classes)):\n",
    "    true_y = test.classes[i]\n",
    "    for l in true_y:\n",
    "        total[l]+=1\n",
    "    predicted_y = np.argwhere(predictions[i]>=0.5)\n",
    "    for p in predicted_y:\n",
    "        if p[0] in true_y:\n",
    "            correct[p[0]]+=1\n",
    "\n",
    "name_id_map = test.class_indices\n",
    "class_names = len(name_id_map)*[0]\n",
    "for k in name_id_map.keys():\n",
    "    class_names[name_id_map[k]] = k\n",
    "            \n",
    "for k in sorted(total.keys()):\n",
    "    print(class_names[k].split(\".\")[-1], \"{}/{} == {}\".format(correct[k], total[k], round(correct[k]/total[k], 3)))\n",
    "                \n",
    "axs[0].set_title('Precision per class')\n",
    "axs[0].barh(range(y_true.shape[1]), sorted_precisions_per_class, color='blue', alpha=0.6)\n",
    "axs[0].set_yticks(range(N_CLASSES))\n",
    "axs[0].set_yticklabels(np.array(list(test.class_indices.keys()))[sorted_indices_precision])\n",
    "axs[0].set_xlabel('Precision')\n",
    "axs[0].grid(True)\n",
    "\n",
    "axs[1].set_title('Recall per class')\n",
    "axs[1].barh(range(y_true.shape[1]), sorted_recalls_per_class, color='blue', alpha=0.6)\n",
    "axs[1].set_yticks(range(N_CLASSES))\n",
    "axs[1].set_yticklabels([])\n",
    "axs[1].set_xlabel('Recall')\n",
    "axs[1].grid(True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b7f323a1c2c8b3d38dc94a01188981c510c9b5df10e2cc2d7fa4f2b45d318cbd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
