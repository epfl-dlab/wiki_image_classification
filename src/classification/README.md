## Abstract
With over 53 million articles and 11 million images, Wikipedia is the greatest encyclopedia in history. The number of users is equally significant, with daily views surpassing 1 billion. Such an enormous system needs automation of tasks to make it possible for the volunteers to maintain. When it comes to textual data, there is a system based on machine learning called *ORES* providing automation to tasks such as article quality estimation and article topic routing. A *visual counterpart system* also needs to be developed to support tasks such as vandalism detection in images and for a better understanding of the visual data of Wikipedia. Researchers from the Wikimedia Foundation identified a hindrance to implementing the visual counterpart of ORES: the images of Wikipedia lack topical metadata. Thus, this work aims at developing a deep learning model that classifies images into a set of topics, which have been pre-determined in parallel work. State-of-the-art image classification models and other methods to mitigate the existing class imbalance are used. The conducted experiments show, among others, that using the data that considers the hierarchy of labels performs better; resampling techniques are ineffective at mitigating imbalance due to the high label concurrence; sample-weighting improves metrics; and thatinitializing parameters as pre-trained on ImageNet rather than randomly yields better metrics. Moreover, we find interesting outlier labels that, despite having fewer samples, obtain better performance metrics, which is believed to be either due to bias from pre-training or simply more signal in the label. The distribution of the visual data predicted by the model is displayed. Finally, some qualitative examples of the model predictions to some images are presented, proving the ability of the model to find correct labels that are missing in the ground truth.

## Code organization
- [create_training_config.ipynb](https://github.com/epfl-dlab/wiki_image_classification/blob/main/classification/Summary.ipynb): creates a [dictionary]([url](https://github.com/epfl-dlab/wiki_image_classification/blob/main/classification/training_configurations.json)) with the different training setups that we ran.
- [clean_and_split_data.py](https://github.com/epfl-dlab/wiki_image_classification/blob/main/classification/CleanAndSplitData.py): filters data from invalid files and splits it into train and test.
- [train_classification.py](https://github.com/epfl-dlab/wiki_image_classification/blob/main/classification/TrainClassification.py): loads the training data and performs the fine-tuning using the already split data. 
- [evaluate.ipynb](https://github.com/epfl-dlab/wiki_image_classification/blob/main/classification/Evaluate.py): loads the test data and the latest training checkpoint and evaluates the model on the test data.
- [get_labels.ipynb](https://github.com/epfl-dlab/wiki_image_classification/blob/main/classification/get_labels.ipynb): 
- [help_functions.py](https://github.com/epfl-dlab/wiki_image_classification/blob/main/classification/help_functions.py): 
