{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Number of classes: 10, 20, 30, 40\n",
    "- Basemodel: EfficientNetB0, EfficientNetB1, Xception\n",
    "- Class weights: true/false\n",
    "- Number of training data\n",
    "- Naive labels vs ORES labels\n",
    "- Affine augmentations of training set\n",
    "<!-- - Dimension to which image is reduced (now 32x32) -->\n",
    "<!-- - Unfrozen layers -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file...\n"
     ]
    }
   ],
   "source": [
    "print('Creating file...')\n",
    "training_configurations = dict()\n",
    "    \n",
    "def create_training_entry(i, \n",
    "                          # Data-level\n",
    "                          augment=False, undersample=False, oversample=False,\n",
    "                          # Algorithm-level\n",
    "                          class_weights=False, per_class_thresh=False, loss_function='binary_crossentropy', \n",
    "                          # Other methods\n",
    "                          random_initialization=False, number_trainable_layers=0,\n",
    "                          hierarchical=False,\n",
    "                          # Training setup\n",
    "                          data_folder='data/split_dataframes_heuristic_labels_20221006', \n",
    "                          epochs=20, \n",
    "                          basemodel='EfficientNetB2', \n",
    "                          nr_classes='all', \n",
    "                          batch_size=512, \n",
    "                          image_dimension=64,\n",
    "                          ):\n",
    "    print(f'Creating {i}th entry in the training_configurations dictionary.')\n",
    "    training_configurations[i] = dict()\n",
    "    # Data-level\n",
    "    training_configurations[i]['augment'] = augment\n",
    "    training_configurations[i]['oversample'] = oversample\n",
    "    training_configurations[i]['undersample'] = undersample\n",
    "\n",
    "    # Algorithm-level\n",
    "    training_configurations[i]['loss_function'] = loss_function\n",
    "    training_configurations[i]['class_weights'] = class_weights\n",
    "    training_configurations[i]['per_class_thresh'] = per_class_thresh\n",
    "\n",
    "    # Others\n",
    "    training_configurations[i]['random_initialization'] = random_initialization\n",
    "    training_configurations[i]['number_trainable_layers'] = number_trainable_layers\n",
    "    training_configurations[i]['hierarchical'] = hierarchical\n",
    "\n",
    "    # Training setup\n",
    "    training_configurations[i]['data_folder'] = data_folder\n",
    "    training_configurations[i]['batch_size'] = batch_size\n",
    "    training_configurations[i]['basemodel'] = basemodel\n",
    "    training_configurations[i]['epochs'] = epochs\n",
    "    training_configurations[i]['nr_classes'] = nr_classes\n",
    "    training_configurations[i]['image_dimension'] = image_dimension\n",
    "\n",
    "    results_folder = f'results_thesis/{i}'\n",
    "    results_folder += '_augment_' if augment == True else ''\n",
    "    results_folder += '_undersample_' if undersample == True else ''\n",
    "    results_folder += '_oversample_' if oversample == True else ''\n",
    "    results_folder += '_class_weights_' if class_weights == True else ''\n",
    "    results_folder += '_random_initialization_' if random_initialization == True else ''\n",
    "    results_folder += f'_bs_{batch_size}'\n",
    "    training_configurations[i]['results_folder'] = results_folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 0th entry in the training_configurations dictionary.\n",
      "Creating 1th entry in the training_configurations dictionary.\n",
      "Creating 10th entry in the training_configurations dictionary.\n",
      "Creating 11th entry in the training_configurations dictionary.\n",
      "Creating 20th entry in the training_configurations dictionary.\n"
     ]
    }
   ],
   "source": [
    "create_training_entry(i=0, random_initialization=False, number_trainable_layers=339)\n",
    "create_training_entry(i=1, random_initialization=True, number_trainable_layers=339)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "create_training_entry(i=10, \n",
    "                      random_initialization=False, \n",
    "                      number_trainable_layers=0, \n",
    "                      batch_size=32, \n",
    "                      undersample=True)\n",
    "\n",
    "create_training_entry(i=11, \n",
    "                      random_initialization=False, \n",
    "                      number_trainable_layers=0, \n",
    "                      batch_size=32, \n",
    "                      oversample=True)\n",
    "\n",
    "create_training_entry(i=20, \n",
    "                      data_folder='data/split_hierarchical_data_221115',\n",
    "                      nr_classes='all')\n",
    "\n",
    "\n",
    "# ==================== DATA-LEVEL TECHNIQUES ====================\n",
    "# 0. Standard transfer-learning setup (BCE loss, 0.5 thresholds, \n",
    "#    equal class-weights, no resampling, no augmentation, weights \n",
    "#    pre-trained on ImageNet, fine-tuning only the extra two layers, \n",
    "#    etc)\n",
    "create_training_entry(i=100, \n",
    "                      # Data-level\n",
    "                      augment=False, undersample=False, oversample=False,\n",
    "                      # Algorithm-level\n",
    "                      class_weights=False, loss_function='binary_crossentropy', per_class_thresh=False,\n",
    "                      # Other methods\n",
    "                      random_initialization=False, number_trainable_layers=0,\n",
    "                      # Training setup\n",
    "                      data_folder='data/split_dataframes_heuristic_labels_20221006', \n",
    "                      epochs=20, \n",
    "                      basemodel='EfficientNetB2',\n",
    "                      nr_classes='all', \n",
    "                      batch_size=512, \n",
    "                      image_dimension=64)\n",
    "\n",
    "# 1. Undersampling\n",
    "create_training_entry(i=101, \n",
    "                      # Data-level\n",
    "                      undersample=True,       augment=False, oversample=False,\n",
    "                      # Algorithm-level\n",
    "                                              class_weights=False, per_class_thresh=False,\n",
    "                      # Other methods\n",
    "                                              random_initialization=False, number_trainable_layers=0,\n",
    "                      # Training setup\n",
    "                      data_folder='data/split_dataframes_heuristic_labels_20221006', \n",
    "                      epochs=20, \n",
    "                      basemodel='EfficientNetB2', \n",
    "                      nr_classes='all', \n",
    "                      batch_size=512, \n",
    "                      loss_function='binary_crossentropy', \n",
    "                      image_dimension=64)\n",
    "\n",
    "# 2. Oversampling\n",
    "create_training_entry(i=102, \n",
    "                      # Data-level -----------------------------------------------------------------\n",
    "                      oversample=True,        augment=False, undersample=False,\n",
    "                      # Algorithm-level ------------------------------------------------------------\n",
    "                                              class_weights=False, per_class_thresh=False,\n",
    "                      # Other methods --------------------------------------------------------------\n",
    "                                              random_initialization=False, number_trainable_layers=0,\n",
    "                      # Training setup -------------------------------------------------------------\n",
    "                      data_folder='data/split_dataframes_heuristic_labels_20221006', \n",
    "                      epochs=20, \n",
    "                      basemodel='EfficientNetB2', \n",
    "                      nr_classes='all', \n",
    "                      batch_size=512, \n",
    "                      loss_function='binary_crossentropy', \n",
    "                      image_dimension=64)\n",
    "\n",
    "# 3. Augmentation\n",
    "create_training_entry(i=103, \n",
    "                      # Data-level -----------------------------------------------------------------\n",
    "                      augment=True,           undersample=False, oversample=False,        \n",
    "                      # Algorithm-level ------------------------------------------------------------\n",
    "                                              class_weights=False, per_class_thresh=False,\n",
    "                      # Other methods --------------------------------------------------------------\n",
    "                                              random_initialization=False, number_trainable_layers=0,\n",
    "                      # Training setup -------------------------------------------------------------\n",
    "                      data_folder='data/split_dataframes_heuristic_labels_20221006', \n",
    "                      epochs=20, \n",
    "                      basemodel='EfficientNetB2', \n",
    "                      nr_classes='all', \n",
    "                      batch_size=512, \n",
    "                      loss_function='binary_crossentropy', \n",
    "                      image_dimension=64)\n",
    "\n",
    "# ==================== ALGORITHM-LEVEL TECHNIQUES ====================\n",
    "# 4. Class-weights\n",
    "create_training_entry(i=104, \n",
    "                      # Data-level\n",
    "                                                augment=False, undersample=False, oversample=False,\n",
    "                      # Algorithm-level\n",
    "                      class_weights=True,       loss_function='binary_crossentropy', per_class_thresh=False,\n",
    "                      # Other methods\n",
    "                                                random_initialization=False, number_trainable_layers=0,\n",
    "                      # Training setup\n",
    "                      data_folder='data/split_dataframes_heuristic_labels_20221006', \n",
    "                      epochs=20, \n",
    "                      basemodel='EfficientNetB2',\n",
    "                      nr_classes='all', \n",
    "                      batch_size=512, \n",
    "                      image_dimension=64)\n",
    "\n",
    "# 5. Per-class thresholds\n",
    "create_training_entry(i=105, \n",
    "                      # Data-level\n",
    "                                                   augment=False, undersample=False, oversample=False,\n",
    "                      # Algorithm-level\n",
    "                      per_class_thresh=True,       class_weights=False, loss_function='binary_crossentropy', \n",
    "                      # Other methods\n",
    "                                                   random_initialization=False, number_trainable_layers=0,\n",
    "                      # Training setup\n",
    "                      data_folder='data/split_dataframes_heuristic_labels_20221006', \n",
    "                      epochs=20, \n",
    "                      basemodel='EfficientNetB2',\n",
    "                      nr_classes='all', \n",
    "                      batch_size=512, \n",
    "                      image_dimension=64)\n",
    "\n",
    "# 6. Loss function\n",
    "create_training_entry(i=106, \n",
    "                      # Data-level\n",
    "                                                   augment=False, undersample=False, oversample=False,\n",
    "                      # Algorithm-level\n",
    "                      loss_function='focal_loss',  per_class_thresh=False, class_weights=False,  \n",
    "                      # Other methods\n",
    "                                                   random_initialization=False, number_trainable_layers=0,\n",
    "                      # Training setup\n",
    "                      data_folder='data/split_dataframes_heuristic_labels_20221006', \n",
    "                      epochs=20, \n",
    "                      basemodel='EfficientNetB2',\n",
    "                      nr_classes='all', \n",
    "                      batch_size=512, \n",
    "                      image_dimension=64)\n",
    "\n",
    "# ==================== OTHER EXPERIMENTS ====================\n",
    "# 7. Randomized weights\n",
    "create_training_entry(i=107, \n",
    "                      # Data-level\n",
    "                                                   augment=False, undersample=False, oversample=False,\n",
    "                      # Algorithm-level\n",
    "                                                   loss_function='binary_crossentropy', per_class_thresh=False, class_weights=False,  \n",
    "                      # Other methods\n",
    "                      random_initialization=True,  number_trainable_layers=0,\n",
    "                      # Training setup\n",
    "                      data_folder='data/split_dataframes_heuristic_labels_20221006', \n",
    "                      epochs=20, \n",
    "                      basemodel='EfficientNetB2',\n",
    "                      nr_classes='all', \n",
    "                      batch_size=512, \n",
    "                      image_dimension=64)\n",
    "\n",
    "# 8. Fine-tuning layers # use the data we already used\n",
    "# create_training_entry(i=108, \n",
    "#                       # Data-level\n",
    "#                                                    augment=False, undersample=False, oversample=False,\n",
    "#                       # Algorithm-level\n",
    "#                                                    loss_function='binary_crossentropy', per_class_thresh=False, class_weights=False,  \n",
    "#                       # Other methods\n",
    "#                       number_trainable_layers=339, random_initialization=False,  \n",
    "#                       # Training setup\n",
    "#                       data_folder='data/split_dataframes_heuristic_labels_20221006', \n",
    "#                       epochs=20, \n",
    "#                       basemodel='EfficientNetB2',\n",
    "#                       nr_classes='all', \n",
    "#                       batch_size=512, \n",
    "#                       image_dimension=64)\n",
    "\n",
    "\n",
    "\n",
    "with open('training_configurations.json', 'w') as fp:\n",
    "    json.dump(training_configurations, fp)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b7f323a1c2c8b3d38dc94a01188981c510c9b5df10e2cc2d7fa4f2b45d318cbd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
