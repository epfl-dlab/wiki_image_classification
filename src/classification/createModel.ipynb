{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB2\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import json\n",
    "import help_functions as hf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_output = (1 - labels) * get_constr_out(output, M) + labels * get_constr_out(labels * output, M)\n",
    "\n",
    "# TODO: add an MCM (maximum constraint module) layer here. Hierarchy constraint expressed in matrix R\n",
    "# it seems the MCM layer only is used at inference? No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 non-validated image filenames belonging to 40 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matvieir/wiki_image_classification/src/classification/help_functions.py:218: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_x_labels['labels'] = df['labels'].apply(lambda labels_list: [label for label in labels_list if label in top_classes])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31925 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "with open('training_configurations.json', 'r') as fp:\n",
    "    config = json.load(fp)[str(1)]\n",
    "\n",
    "config['batch_size'] = 1\n",
    "config['nr_classes'] = 2\n",
    "test = hf.get_flow(df_file=config['data_folder'] + '/test_df.json.bz2',\n",
    "                   nr_classes=config['nr_classes'],\n",
    "                   batch_size=config['batch_size'],\n",
    "                   image_dimension=config['image_dimension'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>categories</th>\n",
       "      <th>labels</th>\n",
       "      <th>naive_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1596792</th>\n",
       "      <td>3915827</td>\n",
       "      <td>Paysage avec deux hommes assis près d'un taill...</td>\n",
       "      <td>a/a8/Paysage_avec_deux_hommes_assis_prÃ¨s_d'un...</td>\n",
       "      <td>[Italian drawings in the Louvre, Everhard Jabach]</td>\n",
       "      <td>[People, Culture, Society]</td>\n",
       "      <td>[Culture, Places]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992788</th>\n",
       "      <td>22139193</td>\n",
       "      <td>Bregoc.JPG</td>\n",
       "      <td>5/55/Bregoc.JPG</td>\n",
       "      <td>[Zelengora]</td>\n",
       "      <td>[Places]</td>\n",
       "      <td>[Places]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                              title  \\\n",
       "1596792   3915827  Paysage avec deux hommes assis près d'un taill...   \n",
       "992788   22139193                                         Bregoc.JPG   \n",
       "\n",
       "                                                       url  \\\n",
       "1596792  a/a8/Paysage_avec_deux_hommes_assis_prÃ¨s_d'un...   \n",
       "992788                                     5/55/Bregoc.JPG   \n",
       "\n",
       "                                                categories  \\\n",
       "1596792  [Italian drawings in the Louvre, Everhard Jabach]   \n",
       "992788                                         [Zelengora]   \n",
       "\n",
       "                             labels       naive_labels  \n",
       "1596792  [People, Culture, Society]  [Culture, Places]  \n",
       "992788                     [Places]           [Places]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read dataframe \n",
    "df = pd.read_json(config['data_folder'] + '/test_df.json.bz2')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the labels to tf.ragged.constant to not get \"ValueError: Can't convert non-rectangular Python sequence to Tensor\" \n",
    "# (https://stackoverflow.com/questions/56304986/valueerror-cant-convert-non-rectangular-python-sequence-to-tensor)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((df.url.values, tf.ragged.constant(df.labels.values))).batch(config['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        x, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = self(x, training=True) # forward pass\n",
    "            # Compute loss\n",
    "            bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "            loss = bce(y, y_pred)\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # Update metrics (includes the metric that tracks the loss)\n",
    "        self.compiled_metrics.update_state(y, y_pred)\n",
    "        # Return a dict mapping metric names to current value\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "def get_uncompiled_model():\n",
    "    basemodel = EfficientNetB2(include_top=False, weights=None, classes=20, input_shape=(32, 32, 3))\n",
    "    inputs = Input(shape=(32, 32, 3))\n",
    "    x = basemodel(inputs)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    outputs = layers.Dense(20, activation='sigmoid')(x)\n",
    "    model = CustomModel(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "def get_compiled_model():\n",
    "    model = get_uncompiled_model()\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# model = get_compiled_model()\n",
    "# model.fit(test, verbose=1, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "basemodel = EfficientNetB2(include_top=False, weights=None, classes=config['nr_classes'], input_shape=(config['image_dimension'], config['image_dimension'], 3))\n",
    "inputs = Input(shape=(config['image_dimension'], config['image_dimension'], 3))\n",
    "x = basemodel(inputs)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "outputs = layers.Dense(config['nr_classes'], activation='sigmoid')(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "# model.compile(optimizer=tf.keras.optimizers.Adam(), metrics=['categorical_accuracy'])\n",
    "loss_fn = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "metrics = tf.metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "tf.Tensor([[[0.81161976 0.70110446]]], shape=(1, 1, 2), dtype=float32)\n",
      "batch_output:\n",
      " [[[0.81161976 0.70110446]\n",
      "  [0.81161976 0.70110446]]]\n",
      "temp:\n",
      " [[[0.         0.        ]\n",
      "  [0.81161976 0.        ]]]\n",
      "tf.Tensor([[0.         0.81161976]], shape=(1, 2), dtype=float32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-afdb5c0f1eb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# Iterate over the batches of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mloss_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;31m# Log every 200 batches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-afdb5c0f1eb4>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(inputs, labels)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Extra steps for coherent HMC:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# 1. max constraint module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mterm_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax_constrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mterm_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax_constrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0my_probs_constrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterm_1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mterm_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# M_ij = 1 if the class i is a subclass of the class j. I.e.: row i, column j is 1.\n",
    "# - note that the diagonal must always be 0, as no class is a subclass of itseld\n",
    "# - note also that if M_ij is 1 then M_ji is necessarily 0 as the subclass relation is not reflexive\n",
    "mask = np.array([[0, 0],\n",
    "                 [1, 0]], dtype=np.float32) # i.e. the second and the third classes are children of the first\n",
    "\n",
    "def max_constrain(output, mask):\n",
    "    \"Constrains the output given the hierarchy expressed by the mask.\"\n",
    "    batch_size = len(output) # or output.shape[0]\n",
    "    nr_classes = mask.shape[0] # = mask.shape[1] = output.shape[1]\n",
    "\n",
    "\n",
    "    output = tf.expand_dims(output, axis=1)\n",
    "    print(output)\n",
    "\n",
    "    batch_output = tf.broadcast_to(output, [batch_size, nr_classes, nr_classes]) # this is H in the MCM equation. Looks good, i.e., as a replication of the predictions in a (nr_classes X nr_classes) matrix\n",
    "    batch_mask = tf.broadcast_to(mask, [batch_size, nr_classes, nr_classes])\n",
    "    temp = batch_output * batch_mask\n",
    "    print(f'batch_output:\\n {batch_output}')\n",
    "    print(f'temp:\\n {temp}')\n",
    "\n",
    "    constrained_output = tf.math.reduce_max(temp, axis=2)\n",
    "    print(constrained_output)\n",
    "    return\n",
    "    return constrained_output\n",
    "\n",
    "# @tf.function\n",
    "def train_step(inputs, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_probs = model(inputs, training=True)\n",
    "\n",
    "        # Extra steps for coherent HMC:\n",
    "        # 1. max constraint module        \n",
    "        term_1 = (1 - labels) * max_constrain(y_probs, mask)\n",
    "        term_2 = labels * max_constrain(labels * y_probs, mask)\n",
    "        y_probs_constrained = term_1 + term_2\n",
    "        # TODO: control if the outputs are indeed coherent, i.e. that a parent class always has greater or equal probability as its children\n",
    "\n",
    "        # 2. modify what is sent to binary cross-entropy function (not anymore y_true and y_probs)\n",
    "        # loss_value = model.compiled_loss(labels, y_probs_constrained)\n",
    "        loss_value = loss_fn(labels, y_probs_constrained)\n",
    "\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    # model.optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    metrics.update_state(labels, y_probs_constrained)\n",
    "    return loss_value\n",
    "    \n",
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    print(f'Start of epoch {epoch}')\n",
    "\n",
    "    # Iterate over the batches of the dataset\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(test):\n",
    "        loss_value = train_step(x_batch_train, y_batch_train)\n",
    "\n",
    "        # Log every 200 batches.\n",
    "        if step % 200 == 0:\n",
    "            print(f\"Training loss (for one batch) at step {step}: {float(loss_value):.4f}\")\n",
    "            print(f\"Seen so far: {(step + 1) * config['batch_size']} samples\")\n",
    "\n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = metrics.result()\n",
    "    # print(f\"Training acc over epoch: {float(train_acc)}\")\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "    metrics.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7f323a1c2c8b3d38dc94a01188981c510c9b5df10e2cc2d7fa4f2b45d318cbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
