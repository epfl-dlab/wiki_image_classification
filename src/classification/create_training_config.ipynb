{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing training configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import help_functions as hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file...\n"
     ]
    }
   ],
   "source": [
    "print('Creating file...')\n",
    "training_configurations = dict()\n",
    "    \n",
    "def create_training_entry(i, \n",
    "                          # Data-level\n",
    "                          augment=False, undersample=False, oversample=False,\n",
    "                          # Algorithm-level\n",
    "                          class_weights=False, per_class_thresh=False, loss_function='binary_crossentropy', \n",
    "                          # Other methods\n",
    "                          random_initialization=False, \n",
    "                          number_trainable_layers='all',\n",
    "                          hierarchical=False,\n",
    "                          # Training setup\n",
    "                          data_folder='', \n",
    "                          epochs=15, \n",
    "                          basemodel='EfficientNetB2', \n",
    "                          batch_size=512, \n",
    "                          image_dimension=64,\n",
    "                          ):\n",
    "    print(f'Creating {i}th entry in the training_configurations dictionary.')\n",
    "    training_configurations[i] = dict()\n",
    "    # Data-level\n",
    "    training_configurations[i]['augment'] = augment\n",
    "    training_configurations[i]['oversample'] = oversample\n",
    "    training_configurations[i]['undersample'] = undersample\n",
    "\n",
    "    # Algorithm-level\n",
    "    training_configurations[i]['loss_function'] = loss_function\n",
    "    training_configurations[i]['class_weights'] = class_weights\n",
    "    training_configurations[i]['per_class_thresh'] = per_class_thresh\n",
    "\n",
    "    # Others\n",
    "    training_configurations[i]['random_initialization'] = random_initialization\n",
    "    training_configurations[i]['number_trainable_layers'] = number_trainable_layers\n",
    "    training_configurations[i]['hierarchical'] = hierarchical\n",
    "\n",
    "    # Training setup\n",
    "    training_configurations[i]['data_folder'] = data_folder\n",
    "    training_configurations[i]['batch_size'] = batch_size\n",
    "    training_configurations[i]['basemodel'] = basemodel\n",
    "    training_configurations[i]['epochs'] = epochs\n",
    "    training_configurations[i]['image_dimension'] = image_dimension\n",
    "\n",
    "    results_folder = f'results_thesis/{i}'\n",
    "    results_folder += '_augment_' if augment == True else ''\n",
    "    results_folder += '_oversample_' if oversample == True else ''\n",
    "    results_folder += '_undersample_' if undersample == True else ''\n",
    "    results_folder += '_class_weights_' if class_weights == True else ''\n",
    "    results_folder += '_bce_' if loss_function == 'binary_crossentropy' else '_' + loss_function + '_'\n",
    "    results_folder += '_hierarchical_model_' if hierarchical == True else ''\n",
    "    results_folder += '_random_initialization_' if random_initialization == True else ''\n",
    "    training_configurations[i]['results_folder'] = results_folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 100th entry in the training_configurations dictionary.\n",
      "Creating 101th entry in the training_configurations dictionary.\n",
      "Creating 102th entry in the training_configurations dictionary.\n",
      "Creating 103th entry in the training_configurations dictionary.\n",
      "Creating 104th entry in the training_configurations dictionary.\n",
      "Creating 105th entry in the training_configurations dictionary.\n",
      "Creating 106th entry in the training_configurations dictionary.\n",
      "Creating 107th entry in the training_configurations dictionary.\n",
      "Creating 108th entry in the training_configurations dictionary.\n",
      "Creating 109th entry in the training_configurations dictionary.\n",
      "Creating 110th entry in the training_configurations dictionary.\n",
      "Creating 111th entry in the training_configurations dictionary.\n",
      "Creating 112th entry in the training_configurations dictionary.\n",
      "Creating 113th entry in the training_configurations dictionary.\n"
     ]
    }
   ],
   "source": [
    "FLAT_LABELS_PATH = 'data/split_flat_data_221216'\n",
    "HIERARCHICAL_LABELS_PATH = 'data/split_hierarchical_data_221218'\n",
    "\n",
    "# ==================== DATA-LEVEL TECHNIQUES ====================\n",
    "# 0. Baseline setup \n",
    "create_training_entry(i=100, data_folder=FLAT_LABELS_PATH)\n",
    "\n",
    "# 1. Undersampling\n",
    "create_training_entry(i=101, undersample=True, data_folder=FLAT_LABELS_PATH)\n",
    "\n",
    "# 2. Oversample + augmentation\n",
    "create_training_entry(i=102, augment=True, oversample=True, data_folder=FLAT_LABELS_PATH)\n",
    "\n",
    "\n",
    "# ==================== ALGORITHM-LEVEL TECHNIQUES ====================\n",
    "# 3. Class-weights\n",
    "create_training_entry(i=103, class_weights=True, data_folder=FLAT_LABELS_PATH)\n",
    "\n",
    "# 4. Sample weight loss\n",
    "create_training_entry(i=104, loss_function='custom_loss', data_folder=FLAT_LABELS_PATH)\n",
    "\n",
    "# 5. Focal loss\n",
    "create_training_entry(i=105, loss_function='focal_loss', data_folder=FLAT_LABELS_PATH)\n",
    "\n",
    "# ==================== OTHER EXPERIMENTS ====================\n",
    "# 6. Randomized weights\n",
    "create_training_entry(i=106, random_initialization=True, data_folder=FLAT_LABELS_PATH)\n",
    "\n",
    "\n",
    "# Study of which data is best: flat or hierarchical\n",
    "\n",
    "# 7. Hierarchical model, hierarchical data\n",
    "create_training_entry(i=107, hierarchical=True, data_folder=HIERARCHICAL_LABELS_PATH)\n",
    "\n",
    "# 8. Hierarchical model, flat data\n",
    "create_training_entry(i=108, hierarchical=True, data_folder=FLAT_LABELS_PATH)\n",
    "\n",
    "# 9. Flat model, hierarchical data\n",
    "create_training_entry(i=109, hierarchical=False, data_folder=HIERARCHICAL_LABELS_PATH)\n",
    "\n",
    "# 10. Flat model, flat data\n",
    "create_training_entry(i=110, hierarchical=False, data_folder=FLAT_LABELS_PATH)\n",
    "\n",
    "\n",
    "with open('training_configurations.json', 'w') as fp:\n",
    "    json.dump(training_configurations, fp)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b7f323a1c2c8b3d38dc94a01188981c510c9b5df10e2cc2d7fa4f2b45d318cbd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2 (default, Mar 26 2020, 15:53:00) \n[GCC 7.3.0]"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
