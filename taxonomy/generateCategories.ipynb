{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76c4818f-bded-4947-87c0-960bfe19575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import urllib\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType, ArrayType\n",
    "from pyspark.accumulators import AccumulatorParam\n",
    "\n",
    "conf = pyspark.SparkConf().setMaster(\"local[4]\").setAll([\n",
    "                                   ('spark.jars.packages', 'com.databricks:spark-xml_2.12:0.8.0'),\n",
    "                                   ('spark.executor.memory', '4g'),\n",
    "                                   ('spark.driver.memory','2g'),\n",
    "                                   ('spark.driver.maxResultSize', '5G'),\n",
    "                                   ('spark.executor.heartbeatInterval', '3600s'),\n",
    "                                   ('spark.network.timeout', '4000s')\n",
    "                                  ])\n",
    "# create the session\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "# create the context\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3decbae-9d5d-44e5-8c4c-2f145f01b90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://128.179.157.207:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x14aadde42e0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e703d84c-8ad2-41cc-b56b-878e156247b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMONS_DUMP_REDUCED = 'commonswiki-20220220-pages-articles-multistream1.xml-p1p1500000.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcb88d1b-3633-45c2-8b12-003f27ae5418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/epfl-dlab/WikiPDA/blob/master/PaperAndCode/TopicsExtractionPipeline/GenerateDataframes.py\n",
    "def normalize_title(title, dumps=True):\n",
    "    \"\"\" Replace _ with space, remove anchor and namespace prefix, capitalize \"\"\"\n",
    "    title = urllib.parse.unquote(title)\n",
    "    if(dumps):\n",
    "        title = title.split(':')[1]\n",
    "    title = title.strip()\n",
    "    if len(title) > 0:\n",
    "        title = title[0].upper() + title[1:]\n",
    "    n_title = title.replace(\"_\", \" \")\n",
    "    if '#' in n_title:\n",
    "        n_title = n_title.split('#')[0]\n",
    "    return n_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8779776f-79a1-4e45-9b0b-8b4b71de4756",
   "metadata": {},
   "source": [
    "## Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7194190e-fb37-41ac-b76f-7f9b0fc29fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, ns: bigint, redirect: struct<_VALUE:string,_title:string>, revision: struct<comment:struct<_VALUE:string,_deleted:string>,contributor:struct<id:bigint,ip:string,username:string>,format:string,id:bigint,minor:string,model:string,parentid:bigint,sha1:string,text:struct<_VALUE:string,_bytes:bigint,_xml:space:string>,timestamp:string>, title: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commons_categories_raw = spark.read.format('com.databricks.spark.xml') \\\n",
    "                                .options(rowTag='page').load(COMMONS_DUMP_REDUCED).filter(\"ns = '14'\")\n",
    "commons_categories_raw.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b404d1e2-de8b-4aff-92e4-da006ea15a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- ns: long (nullable = true)\n",
      " |-- redirect: struct (nullable = true)\n",
      " |    |-- _VALUE: string (nullable = true)\n",
      " |    |-- _title: string (nullable = true)\n",
      " |-- revision: struct (nullable = true)\n",
      " |    |-- comment: struct (nullable = true)\n",
      " |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |-- _deleted: string (nullable = true)\n",
      " |    |-- contributor: struct (nullable = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- ip: string (nullable = true)\n",
      " |    |    |-- username: string (nullable = true)\n",
      " |    |-- format: string (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- minor: string (nullable = true)\n",
      " |    |-- model: string (nullable = true)\n",
      " |    |-- parentid: long (nullable = true)\n",
      " |    |-- sha1: string (nullable = true)\n",
      " |    |-- text: struct (nullable = true)\n",
      " |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |-- _bytes: long (nullable = true)\n",
      " |    |    |-- _xml:space: string (nullable = true)\n",
      " |    |-- timestamp: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "commons_categories_raw.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe4ed0e3-1bac-4dc2-a40f-6aa122a6bf6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Architectural styles': 'Architecture by style',\n",
       " 'The United States': 'United States',\n",
       " '23rd Street, New York City': '23rd Street (Manhattan)',\n",
       " 'Madison Square': 'Madison Square and Madison Square Park',\n",
       " 'San Francisco, California': 'San Francisco',\n",
       " 'C-54 Skymaster': 'Douglas C-54 Skymaster',\n",
       " 'Tunnels in nature': 'Tunnels',\n",
       " 'Boulevard Saint-Germain': 'Boulevard Saint-Germain (Paris)',\n",
       " 'Hudson Heights': 'Hudson Heights, Manhattan',\n",
       " 'CAT': 'Categories',\n",
       " 'Washington Heights': 'Washington Heights, Manhattan'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a dictionary of redirects\n",
    "category_redirects = {normalize_title(r.title): normalize_title(r.redirect._title) \n",
    "                      for r in commons_categories_raw.filter('redirect is not null').collect()}\n",
    "category_redirects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57f5b9ed-8f71-4725-86fb-39a5745d1072",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_regex = re.compile('\\[\\[Category:([^\\|]*?)(?:\\|.*?)*\\]\\]')\n",
    "hiddencat_regex = re.compile('__HIDDENCAT__')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55b6d41d-d11d-4ff8-ad2c-ba7f2c431073",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChildsAccumulator(AccumulatorParam):\n",
    "    '''\n",
    "    Accumulator for childs: a dictionary mapping each category to its childs\n",
    "    '''\n",
    "    def zero(self, value):\n",
    "        return defaultdict(list)\n",
    "\n",
    "    def addInPlace(self, val1, val2):\n",
    "        for key, value in val2.items():\n",
    "            val1[key] += value\n",
    "        return val1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03bf2dad-11f8-4400-8304-7d767b297193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_category(row):\n",
    "    '''\n",
    "    Extract the details of a category\n",
    "    '''\n",
    "    title=normalize_title(row.title)\n",
    "    text=row.revision.text._VALUE\n",
    "    parents=re.findall(categories_regex, text) if text else []\n",
    "    parents=[category_redirects[parent] if parent in category_redirects.keys() else parent for parent in parents]\n",
    "    global acc\n",
    "    if parents:\n",
    "        acc += {parent: [title] for parent in parents}\n",
    "    return Row(\n",
    "        id=row.id,\n",
    "        title=title,\n",
    "        parents=parents,\n",
    "        hiddencat=re.search(hiddencat_regex, text) is not None if text else False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "562fa86b-1ed3-4d36-84cc-76d3d16a79b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema of the processed categories DataFrame\n",
    "schema_cat = StructType([StructField(\"id\", IntegerType(), True),\n",
    "                         StructField(\"title\", StringType(), True),\n",
    "                         StructField(\"parents\", ArrayType(StringType()), True),\n",
    "                         StructField(\"hiddencat\", BooleanType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd88f17e-9c3a-432a-bd73-8e10848623e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We ignore redirect categories, eventually remapping parents to their redirects\n",
    "acc = sc.accumulator(defaultdict(list), ChildsAccumulator())\n",
    "categories_clean = spark.createDataFrame(commons_categories_raw.filter('redirect is null')\\\n",
    "                                            .rdd.map(extract_category).filter(lambda r: r is not None), \n",
    "                                         schema=schema_cat)\n",
    "\n",
    "commons_categories_raw.unpersist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ca709dc-e7d5-4391-98ea-6dbc6c69888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_childs = StructType([StructField('title', StringType(), True),\n",
    "                            StructField('childs', ArrayType(StringType(), True), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60848465-2d30-4ac9-b6e9-9f7138b5e389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround for the fact that the value of acc is used before it is filled, need to fix this.\n",
    "categories_clean.cache().collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b54405a-86cc-4617-a770-75987e4f0415",
   "metadata": {},
   "outputs": [],
   "source": [
    "childs_df = spark.createDataFrame(acc.value.items(), schema=schema_childs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1291a1a4-a05f-4480-b23a-24971a5f82a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = categories_clean.alias('c').join(childs_df, categories_clean.title==childs_df.title).select('c.*', 'childs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d881abd-86c6-4fe8-9cab-65a18d027466",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cba5ca-1e47-4740-beb3-7cd854dd3cde",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ae495bfe-99a2-4735-b105-cfc50d424494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, ns: bigint, redirect: struct<_VALUE:string,_title:string>, revision: struct<comment:struct<_VALUE:string,_deleted:string>,contributor:struct<id:bigint,ip:string,username:string>,format:string,id:bigint,minor:string,model:string,parentid:bigint,sha1:string,text:struct<_VALUE:string,_bytes:bigint,_xml:space:string>,timestamp:string>, title: string]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commons_files_raw = spark.read.format('com.databricks.spark.xml') \\\n",
    "                                .options(rowTag='page').load(COMMONS_DUMP_REDUCED)\\\n",
    "                                .filter(\"ns = '6'\")\n",
    "commons_files_raw.persist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0437442b-9d70-4a6f-a20c-bd386a343332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GDR Army OF9 Generalleutnant.gif': 'GDR Air Force OF7 Generalleutnant.gif',\n",
       " 'Empress-Dowager-Cixi2.jpg': 'Empress Dowager Cixi (c. 1890).jpg'}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a dictionary of redirects\n",
    "file_redirects = {normalize_title(r.title): normalize_title(r.redirect._title)\n",
    "                  for r in commons_files_raw.filter('redirect is not null').collect()}\n",
    "file_redirects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a698ca9-9a92-40ec-8d44-0148c12050f5",
   "metadata": {},
   "source": [
    "For now, we consider only the images that appear in en.wikipedia, discarding all the others. We can also ignore redirects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "267b2020-c612-46be-bfb4-186777288da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of chunks of the dataset\n",
    "WIT_DATASET = ['wit_v1.train.all-1percent_sample.tsv.gz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a214f82d-6ea7-4fc5-9bb6-7d8746af67be",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_image_names = []\n",
    "\n",
    "for chunk in WIT_DATASET:\n",
    "    wiki_image_names += pd.read_csv(chunk, sep=\"\\t\").query(\"language == 'en'\")\\\n",
    "                            .image_url.apply(lambda r: normalize_title(r.split('/')[-1], False)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "21abc0dd-f651-444a-95c5-6c9bb7cde966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only unique values\n",
    "wiki_image_names = set(wiki_image_names)\n",
    "\n",
    "# Remap redirects\n",
    "wiki_image_names = {file_redirects[name] if name in file_redirects.keys() else name for name in wiki_image_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "6412de9f-8ad7-4c82-b49f-2599081fc790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file(row):\n",
    "    '''\n",
    "    Extract the details of a file\n",
    "    '''\n",
    "    text=row.revision.text._VALUE\n",
    "    categories=re.findall(categories_regex, text) if text else []\n",
    "    # No way to do this with a list comprehension (nested conditions work only if there is always an else)\n",
    "    categories_nohidd = []\n",
    "    for category in categories:\n",
    "        if(category not in hidden_categories):\n",
    "            if(category in category_redirects.keys()):\n",
    "                if((c:=category_redirects[category]) not in hidden_categories):\n",
    "                    categories_nohidd.append(c)\n",
    "            else:\n",
    "                categories_nohidd.append(category)\n",
    "\n",
    "    return Row(\n",
    "        id=row.id,\n",
    "        title=normalize_title(row.title),\n",
    "        categories = categories_nohidd\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "d08b05a6-7d88-4dfb-a937-2387898b8002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema of the processed files DataFrame\n",
    "schema_files = StructType([StructField(\"id\", IntegerType(), True),\n",
    "                           StructField(\"title\", StringType(), True),\n",
    "                           StructField(\"categories\", ArrayType(StringType()), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "db49e495-8be0-465e-8d87-9e9ca4f82ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also for files, we ignore redirects\n",
    "files_clean = spark.createDataFrame(commons_files_raw.filter('redirect is null')\\\n",
    "                                            .rdd.map(extract_file).filter(lambda r: r is not None), \n",
    "                                    schema=schema_files)\n",
    "commons_files_raw.unpersist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "e6c70bc7-9550-4e13-a5f2-6e7568b0d00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| id|               title|          categories|\n",
      "+---+--------------------+--------------------+\n",
      "| 26|Two Gambel's Quai...|[Callipepla gambe...|\n",
      "| 30|          Quail2.png|[Callipepla gambe...|\n",
      "| 56|         Kane QC.png|[Computer diagram...|\n",
      "| 62|The Death of Hyac...|[Paintings of nud...|\n",
      "| 73|     BordUtrecht.jpg|[Utrecht Central ...|\n",
      "| 76|         Bustaxi.jpg|[Public transport...|\n",
      "| 80|      Buswachten.jpg|[Station Assen, B...|\n",
      "| 81|          Lijn10.jpg|[Assen, Arriva Pe...|\n",
      "| 82|          Lijn51.jpg|[Den Oudsten B88,...|\n",
      "| 85|Groninger-museum.jpg|[Groninger Museum...|\n",
      "| 87|   Groningen 003.jpg|[Der Aa-kerk, Kor...|\n",
      "| 93|De Slegte, Gronin...|[Buildings in Gro...|\n",
      "| 95|     Hunebed 001.jpg|[Hunebed D25 in B...|\n",
      "| 96|     Hunebed 002.jpg|[Hunebed D25 in B...|\n",
      "| 97|     Hunebed 003.jpg|[Hunebed D24 in B...|\n",
      "| 98|     Hunebed 004.jpg|[Hunebed D21 in B...|\n",
      "| 99|     Hunebed 005.jpg|[Hunebed D21 in B...|\n",
      "|100|     Hunebed 006.jpg|[Hunebed D27 in B...|\n",
      "|101|     Hunebed 008.jpg|[Hunebed D27 in B...|\n",
      "|102|     Hunebed 010.jpg|[Hunebed D27 in B...|\n",
      "+---+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files_clean.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
