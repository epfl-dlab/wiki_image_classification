{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df6482d-26a7-45b6-a626-deea581d9901",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/frasalvi/wikitextprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76c4818f-bded-4947-87c0-960bfe19575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import urllib\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import wikitextprocessor as wtp\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType, ArrayType\n",
    "from pyspark.accumulators import AccumulatorParam\n",
    "\n",
    "conf = pyspark.SparkConf().setMaster(\"local[4]\").setAll([\n",
    "                                   ('spark.jars.packages', 'com.databricks:spark-xml_2.12:0.8.0'),\n",
    "                                   ('spark.executor.memory', '4g'),\n",
    "                                   ('spark.driver.memory','2g'),\n",
    "                                   ('spark.driver.maxResultSize', '5G'),\n",
    "                                   ('spark.executor.heartbeatInterval', '3600s'),\n",
    "                                   ('spark.network.timeout', '4000s')\n",
    "                                  ])\n",
    "# create the session\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "# create the context\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3decbae-9d5d-44e5-8c4c-2f145f01b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e703d84c-8ad2-41cc-b56b-878e156247b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMONS_DUMP_REDUCED = 'commonswiki-20220220-pages-articles-multistream1.xml-p1p1500000.bz2'\n",
    "COMMONS_DUMP_REDUCED = 'commonswiki-20220220-pages-articles-multistream6.xml-p114543930p115400363.bz2'\n",
    "TEMPLATES_DUMP = 'commonswiki-20220220-templates-modules.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcb88d1b-3633-45c2-8b12-003f27ae5418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/epfl-dlab/WikiPDA/blob/master/PaperAndCode/TopicsExtractionPipeline/GenerateDataframes.py\n",
    "def normalize_title(title, dumps=True):\n",
    "    \"\"\" Replace _ with space, remove anchor and namespace prefix, capitalize \"\"\"\n",
    "    title = urllib.parse.unquote(title)\n",
    "    if(dumps):\n",
    "        title = title.split(':')[1]\n",
    "    title = title.strip()\n",
    "    if len(title) > 0:\n",
    "        title = title[0].upper() + title[1:]\n",
    "    n_title = title.replace(\"_\", \" \")\n",
    "    if '#' in n_title:\n",
    "        n_title = n_title.split('#')[0]\n",
    "    return n_title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ed8b68-1a3b-41e2-8655-bc1a19f559f6",
   "metadata": {},
   "source": [
    "## Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7a4331fd-5774-4098-9ecd-deb56cf05eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/tatuylonen/wikitextprocessor/blob/ee043cff190543fb94cb40d4827444d8982a30fe/wikitextprocessor/core.py#L490\n",
    "def template_to_body(title, text):\n",
    "        \"\"\"Extracts the portion to be transcluded from a template body.  This\n",
    "        returns an str.\"\"\"\n",
    "        assert isinstance(title, str)\n",
    "        assert isinstance(text, str)\n",
    "        # Remove all comments\n",
    "        text = re.sub(r\"(?s)<!\\s*--.*?--\\s*>\", \"\", text)\n",
    "        # Remove all text inside <noinclude> ... </noinclude>\n",
    "        text = re.sub(r\"(?is)<\\s*noinclude\\s*>.*?<\\s*/\\s*noinclude\\s*>\",\n",
    "                      \"\", text)\n",
    "        # Handle <noinclude> without matching </noinclude> by removing the\n",
    "        # rest of the file\n",
    "        text = re.sub(r\"(?is)<\\s*noinclude\\s*>.*\", \"\", text)\n",
    "        text = re.sub(r\"(?is)<\\s*noinclude\\s*/\\s*>\", \"\", text)\n",
    "        # Apparently unclosed <!-- at the end of a template body is ignored\n",
    "        text = re.sub(r\"(?s)<!\\s*--.*\", \"\", text)\n",
    "        # <onlyinclude> tags, if present, include the only text that will be\n",
    "        # transcluded.  All other text is ignored.\n",
    "        onlys = list(re.finditer(r\"(?is)<\\s*onlyinclude\\s*>(.*?)\"\n",
    "                                 r\"<\\s*/\\s*onlyinclude\\s*>|\"\n",
    "                                 r\"<\\s*onlyinclude\\s*/\\s*>\",\n",
    "                                 text))\n",
    "        if onlys:\n",
    "            text = \"\".join(m.group(1) or \"\" for m in onlys)\n",
    "        # Remove <includeonly>.  They mark text that is not visible on the page\n",
    "        # itself but is included in transclusion.  Also text outside these tags\n",
    "        # is included in transclusion.\n",
    "        text = re.sub(r\"(?is)<\\s*(/\\s*)?includeonly\\s*(/\\s*)?>\", \"\", text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "51cdda1a-2106-40a7-b355-2bbd08f7699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize = 1\n",
    "\n",
    "if initialize:\n",
    "    commons_templates_modules = spark.read.format('com.databricks.spark.xml') \\\n",
    "                                        .options(rowTag='page').load(COMMONS_DUMP_REDUCED).filter(\"ns = '10' or ns = '828'\")\n",
    "    commons_templates_modules.write.format(\"com.databricks.spark.xml\").mode(\"overwrite\")\\\n",
    "                                   .options(rowTag='page', rootTag='pages').save(TEMPLATES_DUMP)\n",
    "    # On windows, CRC parts must then be merged manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f54b24c7-4359-41e7-9f3a-7921e5f52f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "templates_categories = spark.read.format(\"com.databricks.spark.xml\")\\\n",
    "                                    .options(rowTag='page').load(TEMPLATES_DUMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06421241-9f9f-401e-85de-a5eb3c340207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_handler(model, title, next):\n",
    "    if not (title.startswith(\"Template:\") or title.startswith(\"Module:\")):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3fd3e176-031b-4192-a414-27487520a5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNSUPPORTED pages 2 {}\n",
      "Analyzing which templates should be expanded before parsing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<generator object Wtp.reprocess at 0x00000258410BFF90>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctx = wtp.Wtp()\n",
    "ctx.process(TEMPLATES_DUMP, page_handler, windows=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93bbba7-de31-402e-8143-13e422346d96",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2572474c-48d8-455d-83c8-fbd825fe1902",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = templates_categories.filter('ns=\"828\"').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "67bbbbcc-c92f-4852-b25c-32b4e9320a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Module:Navbox with collapsible groups',\n",
       " 'Module:Navbox with collapsible groups/doc',\n",
       " 'Module:Navboxes',\n",
       " 'Module:PermissionTicket',\n",
       " 'Module:PermissionTicket/doc',\n",
       " 'Module:PermissionTicket/testcases',\n",
       " 'Module:PermissionTicket/testcases/doc',\n",
       " 'Module:RomanNumber',\n",
       " 'Module:Contributor/sandbox']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: x.title, aa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cd1520fb-b07b-471a-852f-f65de97729b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'ciao bello {{global maintenance category}} come stai?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3e2138a0-1ce9-4f6d-851a-6e921a3debb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_gmc = template_to_body('global maintenance category', '{{autotranslate|1={{{shortcut|{{{1|}}} }}}|purge={{{purge|}}}|base=Global maintenance category/i18n}}<includeonly>{{#ifeq:{{{hidden|}}}|n||__HIDDENCAT__}}</includeonly><noinclude>{{documentation}}</noinclude>')\n",
    "body_autotrans = template_to_body('autotranslate', '<includeonly>{{#invoke:PermissionTicket|PermissionTicket|id=2022011910011071|nocat=1}}<!--  -->{{#ifeq: {{FULLPAGENAME}} |Template:{{{base|}}} |[[Category:Autotranslated templates|{{PAGENAME}}]]}}</includeonly><noinclude>{{Documentation}}</noinclude>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d6a6f8cd-db33-437c-88e2-5744d55eeaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "templates_dict = {'global maintenance category': body_gmc, 'autotranslate': body_autotrans}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b2bfbe8f-0d30-4aa7-8f96-fbe79eb81ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.assign_templates(templates_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d2cfbe72-1c31-4d7b-8e98-9fc3e5f2283b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'os' has no attribute 'pread'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_240/1769582487.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'prova'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\ProgramsAltri\\anaconda3\\envs\\ada\\lib\\site-packages\\wikitextprocessor\\core.py\u001b[0m in \u001b[0;36mexpand\u001b[1;34m(self, text, title, parent, pre_expand, template_fn, post_template_fn, templates_to_expand, expand_parserfns, expand_invoke, quiet, timeout)\u001b[0m\n\u001b[0;32m   1243\u001b[0m         \u001b[1;31m# Recursively expand the selected templates.  This is an outside-in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m         \u001b[1;31m# operation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1245\u001b[1;33m         \u001b[0mexpanded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexpand_recurse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemplates_to_expand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1247\u001b[0m         \u001b[1;31m# Expand any remaining magic cookies and remove nowiki char\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ProgramsAltri\\anaconda3\\envs\\ada\\lib\\site-packages\\wikitextprocessor\\core.py\u001b[0m in \u001b[0;36mexpand_recurse\u001b[1;34m(coded, parent, templates_to_expand)\u001b[0m\n\u001b[0;32m   1191\u001b[0m                         \u001b[1;31m# next iteration anyway (assuming parent unchanged)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m                         \u001b[1;31m# Otherwise expand the body\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1193\u001b[1;33m                         t = expand_recurse(encoded_body, new_parent,\n\u001b[0m\u001b[0;32m   1194\u001b[0m                                            templates_to_expand)\n\u001b[0;32m   1195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ProgramsAltri\\anaconda3\\envs\\ada\\lib\\site-packages\\wikitextprocessor\\core.py\u001b[0m in \u001b[0;36mexpand_recurse\u001b[1;34m(coded, parent, templates_to_expand)\u001b[0m\n\u001b[0;32m   1191\u001b[0m                         \u001b[1;31m# next iteration anyway (assuming parent unchanged)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m                         \u001b[1;31m# Otherwise expand the body\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1193\u001b[1;33m                         t = expand_recurse(encoded_body, new_parent,\n\u001b[0m\u001b[0;32m   1194\u001b[0m                                            templates_to_expand)\n\u001b[0;32m   1195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ProgramsAltri\\anaconda3\\envs\\ada\\lib\\site-packages\\wikitextprocessor\\core.py\u001b[0m in \u001b[0;36mexpand_recurse\u001b[1;34m(coded, parent, templates_to_expand)\u001b[0m\n\u001b[0;32m   1058\u001b[0m                         if (fn_name in PARSER_FUNCTIONS or\n\u001b[0;32m   1059\u001b[0m                             fn_name.startswith(\"#\")):\n\u001b[1;32m-> 1060\u001b[1;33m                             ret = expand_parserfn(fn_name,\n\u001b[0m\u001b[0;32m   1061\u001b[0m                                                   \u001b[1;33m(\u001b[0m\u001b[0mtname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mofs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m                                                   args[1:])\n",
      "\u001b[1;32m~\\ProgramsAltri\\anaconda3\\envs\\ada\\lib\\site-packages\\wikitextprocessor\\core.py\u001b[0m in \u001b[0;36mexpand_parserfn\u001b[1;34m(fn_name, args)\u001b[0m\n\u001b[0;32m    996\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mexpand_invoke\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m                         \u001b[1;32mreturn\u001b[0m \u001b[1;34m\"{{#invoke:\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"|\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"}}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 998\u001b[1;33m                     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minvoke_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpander\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    999\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m                     \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_parser_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpander\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ProgramsAltri\\anaconda3\\envs\\ada\\lib\\site-packages\\wikitextprocessor\\core.py\u001b[0m in \u001b[0;36minvoke_fn\u001b[1;34m(invoke_args, expander, parent)\u001b[0m\n\u001b[0;32m    898\u001b[0m             \u001b[1;31m# the Lua environment and store it in self.lua if it does not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m             \u001b[1;31m# already exist (it needs to be re-created for each new page).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 900\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_lua_sandbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minvoke_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpander\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    901\u001b[0m             \u001b[1;31m# print(\"invoke_fn: invoke_args={} parent={} LUA ret={!r}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[1;31m#       .format(invoke_args, parent, ret))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ProgramsAltri\\anaconda3\\envs\\ada\\lib\\site-packages\\wikitextprocessor\\luaexec.py\u001b[0m in \u001b[0;36mcall_lua_sandbox\u001b[1;34m(ctx, invoke_args, expander, parent, timeout)\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_stack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Lua:{}:{}()\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlua_invoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m             \u001b[0mok\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mlupa\\_lupa.pyx\u001b[0m in \u001b[0;36mlupa._lupa._LuaObject.__call__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mlupa\\_lupa.pyx\u001b[0m in \u001b[0;36mlupa._lupa.call_lua\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mlupa\\_lupa.pyx\u001b[0m in \u001b[0;36mlupa._lupa.execute_lua_call\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mlupa\\_lupa.pyx\u001b[0m in \u001b[0;36mlupa._lupa.LuaRuntime.reraise_on_exception\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mlupa\\_lupa.pyx\u001b[0m in \u001b[0;36mlupa._lupa.py_call_with_gil\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mlupa\\_lupa.pyx\u001b[0m in \u001b[0;36mlupa._lupa.call_python\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\ProgramsAltri\\anaconda3\\envs\\ada\\lib\\site-packages\\wikitextprocessor\\luaexec.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[0mset_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlua\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlua_sandbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[1;31m# Call the function that sets the Lua loader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m     \u001b[0mset_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlua_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m     \u001b[1;31m# Then load the second phase of the sandbox.  This now goes through the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ProgramsAltri\\anaconda3\\envs\\ada\\lib\\site-packages\\wikitextprocessor\\luaexec.py\u001b[0m in \u001b[0;36mlua_loader\u001b[1;34m(ctx, modname)\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_by_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;31m# Try to load it from a file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\ProgramsAltri\\anaconda3\\envs\\ada\\lib\\site-packages\\wikitextprocessor\\core.py\u001b[0m in \u001b[0;36mread_by_title\u001b[1;34m(self, title)\u001b[0m\n\u001b[0;32m   1419\u001b[0m         \u001b[1;31m# might cause a race condition with parallel scanning of the temporary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m         \u001b[1;31m# file.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1421\u001b[1;33m         \u001b[0mrawdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtmp_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpage_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mofs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1422\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mrawdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'os' has no attribute 'pread'"
     ]
    }
   ],
   "source": [
    "ctx.expand(text, title='prova')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff9e356-a201-4e56-af32-15d5908a6e40",
   "metadata": {},
   "source": [
    "## Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba4845f-bf35-4e09-9408-400b9e571eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "commons_categories_raw = spark.read.format('com.databricks.spark.xml') \\\n",
    "                                .options(rowTag='page').load(COMMONS_DUMP_REDUCED).filter(\"ns = '14'\")\n",
    "commons_categories_raw.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b404d1e2-de8b-4aff-92e4-da006ea15a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- ns: long (nullable = true)\n",
      " |-- redirect: struct (nullable = true)\n",
      " |    |-- _VALUE: string (nullable = true)\n",
      " |    |-- _title: string (nullable = true)\n",
      " |-- revision: struct (nullable = true)\n",
      " |    |-- comment: struct (nullable = true)\n",
      " |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |-- _deleted: string (nullable = true)\n",
      " |    |-- contributor: struct (nullable = true)\n",
      " |    |    |-- id: long (nullable = true)\n",
      " |    |    |-- ip: string (nullable = true)\n",
      " |    |    |-- username: string (nullable = true)\n",
      " |    |-- format: string (nullable = true)\n",
      " |    |-- id: long (nullable = true)\n",
      " |    |-- minor: string (nullable = true)\n",
      " |    |-- model: string (nullable = true)\n",
      " |    |-- parentid: long (nullable = true)\n",
      " |    |-- sha1: string (nullable = true)\n",
      " |    |-- text: struct (nullable = true)\n",
      " |    |    |-- _VALUE: string (nullable = true)\n",
      " |    |    |-- _bytes: long (nullable = true)\n",
      " |    |    |-- _xml:space: string (nullable = true)\n",
      " |    |-- timestamp: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "commons_categories_raw.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8779776f-79a1-4e45-9b0b-8b4b71de4756",
   "metadata": {},
   "source": [
    "## Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7194190e-fb37-41ac-b76f-7f9b0fc29fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, ns: bigint, redirect: struct<_VALUE:string,_title:string>, revision: struct<comment:struct<_VALUE:string,_deleted:string>,contributor:struct<id:bigint,ip:string,username:string>,format:string,id:bigint,minor:string,model:string,parentid:bigint,sha1:string,text:struct<_VALUE:string,_bytes:bigint,_xml:space:string>,timestamp:string>, title: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commons_categories_raw = spark.read.format('com.databricks.spark.xml') \\\n",
    "                                .options(rowTag='page').load(COMMONS_DUMP_REDUCED).filter(\"ns = '14'\")\n",
    "commons_categories_raw.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55b6d41d-d11d-4ff8-ad2c-ba7f2c431073",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChildsAccumulator(AccumulatorParam):\n",
    "    '''\n",
    "    Accumulator for childs: a dictionary mapping each category to its childs\n",
    "    '''\n",
    "    def zero(self, value):\n",
    "        return defaultdict(list)\n",
    "\n",
    "    def addInPlace(self, val1, val2):\n",
    "        for key, value in val2.items():\n",
    "            val1[key] += value\n",
    "        return val1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03bf2dad-11f8-4400-8304-7d767b297193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_category(row):\n",
    "    '''\n",
    "    Extract the details of a category\n",
    "    '''\n",
    "    title=normalize_title(row.title)\n",
    "    text=row.revision.text._VALUE\n",
    "    parents=re.findall(categories_regex, text) if text else []\n",
    "    parents=[category_redirects[parent] if parent in category_redirects.keys() else parent for parent in parents]\n",
    "    global acc\n",
    "    if parents:\n",
    "        acc += {parent: [title] for parent in parents}\n",
    "    return Row(\n",
    "        id=row.id,\n",
    "        title=title,\n",
    "        parents=parents,\n",
    "        hiddencat=re.search(hiddencat_regex, text) is not None if text else False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "562fa86b-1ed3-4d36-84cc-76d3d16a79b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema of the processed categories DataFrame\n",
    "schema_cat = StructType([StructField(\"id\", IntegerType(), True),\n",
    "                         StructField(\"title\", StringType(), True),\n",
    "                         StructField(\"parents\", ArrayType(StringType()), True),\n",
    "                         StructField(\"hiddencat\", BooleanType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd88f17e-9c3a-432a-bd73-8e10848623e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We ignore redirect categories, eventually remapping parents to their redirects\n",
    "acc = sc.accumulator(defaultdict(list), ChildsAccumulator())\n",
    "categories_clean = spark.createDataFrame(commons_categories_raw.filter('redirect is null')\\\n",
    "                                            .rdd.map(extract_category).filter(lambda r: r is not None), \n",
    "                                         schema=schema_cat)\n",
    "\n",
    "commons_categories_raw.unpersist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ca709dc-e7d5-4391-98ea-6dbc6c69888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_childs = StructType([StructField('title', StringType(), True),\n",
    "                            StructField('childs', ArrayType(StringType(), True), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60848465-2d30-4ac9-b6e9-9f7138b5e389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Workaround for the fact that the value of acc is used before it is filled, need to fix this.\n",
    "categories_clean.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b54405a-86cc-4617-a770-75987e4f0415",
   "metadata": {},
   "outputs": [],
   "source": [
    "childs_df = spark.createDataFrame(acc.value.items(), schema=schema_childs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1291a1a4-a05f-4480-b23a-24971a5f82a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = categories_clean.alias('c').join(childs_df, categories_clean.title==childs_df.title).select('c.*', 'childs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d881abd-86c6-4fe8-9cab-65a18d027466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, title: string, parents: array<string>, hiddencat: boolean, childs: array<string>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8aaa645e-3028-4e98-a1da-0010cdbb4aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_categories = categories.filter('hiddencat is True').select('title').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "105b43b1-da14-42e7-b0a3-71562e36f974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GFDL',\n",
       " 'Flickr review needed',\n",
       " 'GPL',\n",
       " 'PD CIA',\n",
       " 'PD US',\n",
       " 'PD US Military',\n",
       " 'PD Germany',\n",
       " 'PD Indonesia',\n",
       " 'CC-BY-2.5',\n",
       " 'PD OpenClipart']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_categories[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cba5ca-1e47-4740-beb3-7cd854dd3cde",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae495bfe-99a2-4735-b105-cfc50d424494",
   "metadata": {},
   "outputs": [],
   "source": [
    "commons_files_raw = spark.read.format('com.databricks.spark.xml') \\\n",
    "                                .options(rowTag='page').load(COMMONS_DUMP_REDUCED)\\\n",
    "                                .filter(\"ns = '6'\")\n",
    "commons_files_raw.persist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0437442b-9d70-4a6f-a20c-bd386a343332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GDR Army OF9 Generalleutnant.gif': 'GDR Air Force OF7 Generalleutnant.gif',\n",
       " 'Empress-Dowager-Cixi2.jpg': 'Empress Dowager Cixi (c. 1890).jpg'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a dictionary of redirects\n",
    "file_redirects = {normalize_title(r.title): normalize_title(r.redirect._title)\n",
    "                  for r in commons_files_raw.filter('redirect is not null').collect()}\n",
    "file_redirects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a698ca9-9a92-40ec-8d44-0148c12050f5",
   "metadata": {},
   "source": [
    "For now, we consider only the images that appear in en.wikipedia, discarding all the others. We can also ignore redirects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "267b2020-c612-46be-bfb4-186777288da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of chunks of the dataset\n",
    "WIT_DATASET = ['wit_v1.train.all-1percent_sample.tsv.gz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a214f82d-6ea7-4fc5-9bb6-7d8746af67be",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_image_names = []\n",
    "\n",
    "for chunk in WIT_DATASET:\n",
    "    wiki_image_names += pd.read_csv(chunk, sep=\"\\t\").query(\"language == 'en'\")\\\n",
    "                            .image_url.apply(lambda r: normalize_title(r.split('/')[-1], False)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "21abc0dd-f651-444a-95c5-6c9bb7cde966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only unique values\n",
    "wiki_image_names = set(wiki_image_names)\n",
    "\n",
    "# Remap redirects\n",
    "wiki_image_names = {file_redirects[name] if name in file_redirects.keys() else name for name in wiki_image_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6412de9f-8ad7-4c82-b49f-2599081fc790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_file(row):\n",
    "    '''\n",
    "    Extract the details of a file\n",
    "    '''\n",
    "    text=row.revision.text._VALUE\n",
    "    categories=re.findall(categories_regex, text) if text else []\n",
    "    # No way to do this with a list comprehension (nested conditions work only if there is always an else)\n",
    "    categories_nohidd = []\n",
    "    for category in categories:\n",
    "        if(category not in hidden_categories):\n",
    "            if(category in category_redirects.keys()):\n",
    "                if((c:=category_redirects[category]) not in hidden_categories):\n",
    "                    categories_nohidd.append(c)\n",
    "            else:\n",
    "                categories_nohidd.append(category)\n",
    "\n",
    "    return Row(\n",
    "        id=row.id,\n",
    "        title=normalize_title(row.title),\n",
    "        categories = categories_nohidd\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d08b05a6-7d88-4dfb-a937-2387898b8002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema of the processed files DataFrame\n",
    "schema_files = StructType([StructField(\"id\", IntegerType(), True),\n",
    "                           StructField(\"title\", StringType(), True),\n",
    "                           StructField(\"categories\", ArrayType(StringType()), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "db49e495-8be0-465e-8d87-9e9ca4f82ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also for files, we ignore redirects\n",
    "files_clean = spark.createDataFrame(commons_files_raw.filter('redirect is null')\\\n",
    "                                            .rdd.map(extract_file).filter(lambda r: r is not None), \n",
    "                                    schema=schema_files)\n",
    "commons_files_raw.unpersist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e6c70bc7-9550-4e13-a5f2-6e7568b0d00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| id|               title|          categories|\n",
      "+---+--------------------+--------------------+\n",
      "| 26|Two Gambel's Quai...|[Callipepla gambe...|\n",
      "| 30|          Quail2.png|[Callipepla gambe...|\n",
      "| 56|         Kane QC.png|[Computer diagram...|\n",
      "| 62|The Death of Hyac...|[Paintings of nud...|\n",
      "| 73|     BordUtrecht.jpg|[Utrecht Central ...|\n",
      "| 76|         Bustaxi.jpg|[Public transport...|\n",
      "| 80|      Buswachten.jpg|[Station Assen, B...|\n",
      "| 81|          Lijn10.jpg|[Assen, Arriva Pe...|\n",
      "| 82|          Lijn51.jpg|[Den Oudsten B88,...|\n",
      "| 85|Groninger-museum.jpg|[Groninger Museum...|\n",
      "| 87|   Groningen 003.jpg|[Der Aa-kerk, Kor...|\n",
      "| 93|De Slegte, Gronin...|[Buildings in Gro...|\n",
      "| 95|     Hunebed 001.jpg|[Hunebed D25 in B...|\n",
      "| 96|     Hunebed 002.jpg|[Hunebed D25 in B...|\n",
      "| 97|     Hunebed 003.jpg|[Hunebed D24 in B...|\n",
      "| 98|     Hunebed 004.jpg|[Hunebed D21 in B...|\n",
      "| 99|     Hunebed 005.jpg|[Hunebed D21 in B...|\n",
      "|100|     Hunebed 006.jpg|[Hunebed D27 in B...|\n",
      "|101|     Hunebed 008.jpg|[Hunebed D27 in B...|\n",
      "|102|     Hunebed 010.jpg|[Hunebed D27 in B...|\n",
      "+---+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files_clean.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3db6c0-c58e-4aac-89f7-c661bb1ead51",
   "metadata": {},
   "source": [
    "## Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b371038-b617-4b6c-93b9-caa9a61f82d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
