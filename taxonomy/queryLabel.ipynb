{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import logging, sys\n",
    "\n",
    "from headParsing import find_head\n",
    "from iteration_utilities import duplicates, unique_everseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)\n",
    "logging.basicConfig(filename='categories.log',\n",
    "                            filemode='w',\n",
    "                            format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                            datefmt='%H:%M:%S',\n",
    "                            level=logging.DEBUG)\n",
    "\n",
    "logging.info(\"Label querying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "CATEGORIES_PATH = '/scratch/WikipediaImagesTaxonomy/commonswiki-20220220-category-network.parquet'\n",
    "FILES_PATH = '/scratch/WikipediaImagesTaxonomy/commonswiki-20220220-files.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Taxonomy:\n",
    "    def __init__(self, G=None):\n",
    "        if(G):\n",
    "            self.G = G\n",
    "\n",
    "    def load_categories(self, path):\n",
    "        '''\n",
    "        Load categories from path and build the category graph.\n",
    "        '''\n",
    "        self.build_category_graph(pd.read_parquet(path))\n",
    "    \n",
    "    def build_category_graph(self, categories):\n",
    "        '''\n",
    "        Build the category graph, starting from the DataFrame extracted by processing dumps\n",
    "        '''\n",
    "        categories = categories.set_index('title')\n",
    "        # Build DiGraph from adjacency matrix\n",
    "        G = nx.DiGraph(categories.parents.to_dict())\n",
    "        nx.set_node_attributes(G, dict(zip(categories.index, categories[['id', 'hiddencat']].to_dict(orient='records'))))\n",
    "        depth = {node: len(sps) for node, sps in nx.shortest_path(G, target='CommonsRoot').items()}\n",
    "        nx.set_node_attributes(G, depth, name='depth')\n",
    "        self.G = G\n",
    "\n",
    "    def reset_labels(self):\n",
    "        '''\n",
    "        Reset labels and discovery status for each node.\n",
    "        '''\n",
    "        nx.set_node_attributes(self.G, {node: {'visited': False, 'labels': set()} for node in self.G.nodes})\n",
    "        self.visited_nodes = 0\n",
    "\n",
    "    def set_taxonomy(self, mapping='content_extended'):\n",
    "        '''\n",
    "        Set an ORES-like taxonomy, mapping labels to high-level categories.\n",
    "        '''\n",
    "        assert isinstance(mapping, dict) or isinstance(mapping, str)\n",
    "\n",
    "        if(isinstance(mapping, dict)):\n",
    "            self.mapping = mapping\n",
    "\n",
    "        elif(mapping == 'content_general'):\n",
    "            self.mapping = {'Nature': ['Animalia', 'Fossils', 'Landscapes', 'Marine organisms', 'Plantae', 'Weather'],\n",
    "                            'Society/Culture': ['Art', 'Belief', 'Entertainment', 'Events', 'Flags', 'Food', 'History', \n",
    "                                                'Language', 'Literature', 'Music', 'Objects', 'People', 'Places', 'Politics', 'Sports'],\n",
    "                            'Science': ['Astronomy', 'Biology', 'Chemistry', 'Earth sciences', 'Mathematics',\n",
    "                                        'Medicine', 'Physics', 'Technology'],\n",
    "                            'Engineering': ['Architecture', 'Chemical engineering', 'Civil engineering', 'Electrical engineering',\n",
    "                                            'Environmental engineering', 'Geophysical engineering', 'Mechanical engineering', 'Process engineering']}\n",
    "\n",
    "        elif(mapping == 'content_extended'):\n",
    "            self.mapping = {# Nature\n",
    "                            'Nature': ['Nature'],\n",
    "                            'Animals': ['Animalia'],\n",
    "                            'Fossils': ['Fossils'],\n",
    "                            'Landscapes': ['Landscapes'],\n",
    "                            'Marine organisms': ['Marine organisms'],\n",
    "                            'Plants': ['Plantae'],\n",
    "                            'Weather': ['Weather'],\n",
    "                            # Society/Culture\n",
    "                            'Society': ['Society'],\n",
    "                            'Culture': ['Culture'],\n",
    "                            'Art': ['Art'],\n",
    "                            'Belief': ['Belief'],\n",
    "                            'Entertainment': ['Entertainment'],\n",
    "                            'Events': ['Events'],\n",
    "                            'Flags': ['Flags'],\n",
    "                            'Food': ['Food'],\n",
    "                            'History': ['History'],\n",
    "                            'Language': ['Language'],\n",
    "                            'Literature': ['Literature'],\n",
    "                            'Music': ['Music'],\n",
    "                            'Objects': ['Objects'],\n",
    "                            'People': ['People'],\n",
    "                            'Places': ['Places'],\n",
    "                            'Politics': ['Politics'],\n",
    "                            'Sports': ['Sports'],\n",
    "                            # Science\n",
    "                            'Science': ['Science'],\n",
    "                            'Astronomy': ['Astronomy'],\n",
    "                            'Biology': ['Biology'],\n",
    "                            'Chemistry': ['Chemistry'],\n",
    "                            'Earth sciences': ['Earth sciences'],\n",
    "                            'Mathematics': ['Mathematics'],\n",
    "                            'Medicine': ['Medicine'],\n",
    "                            'Physics': ['Physics'],\n",
    "                            'Technology': ['Technology'],\n",
    "                            # Engineering\n",
    "                            'Engineering': ['Engineering'],\n",
    "                            'Architecture': ['Architecture'],\n",
    "                            'Chemical eng': ['Chemical engineering'],\n",
    "                            'Civil eng': ['Civil engineering'],\n",
    "                            'Electrical eng': ['Electrical engineering'],\n",
    "                            'Environmental eng': ['Environmental engineering'],\n",
    "                            'Geophysical eng': ['Geophysical engineering'],\n",
    "                            'Mechanical eng': ['Mechanical engineering'],\n",
    "                            'Process eng': ['Process engineering']\n",
    "                            }\n",
    "        else:\n",
    "            raise ValueError('Invalid mapping')\n",
    "\n",
    "        self.reset_labels()\n",
    "        for label, categories in self.mapping.items():\n",
    "            for category in categories:\n",
    "                self.visited_nodes += 1\n",
    "                self.G.nodes[category]['visited'] = True\n",
    "                self.G.nodes[category]['labels'].add(label)\n",
    "    \n",
    "    def get_head(self, category):\n",
    "        '''\n",
    "        Get or compute the lexical head of a given category.\n",
    "        '''\n",
    "        if('head' in self.G.nodes[category]):\n",
    "            head = self.G.nodes[category]['head']\n",
    "        else:\n",
    "            head = find_head(category)\n",
    "            self.G.nodes[category]['head'] = head\n",
    "        return head\n",
    "\n",
    "\n",
    "    def get_label(self, category, how='heuristics'):\n",
    "        '''\n",
    "        Get the label corresponding to a specific category, passed as string.\n",
    "\n",
    "        Params:\n",
    "            how (string): decision scheme to recursively query parents. \n",
    "                all: all parents are queried\n",
    "                naive: hop only to lower-depth parents\n",
    "                heuristics: decision based on the set of heuristics described in ??\n",
    "        '''\n",
    "        assert isinstance(category, str)\n",
    "\n",
    "        if(self.G.nodes[category]['visited']):\n",
    "            logging.debug('Found ' + category + ' with label ' + str(self.G.nodes[category]['labels']))\n",
    "            return self.G.nodes[category]['labels']\n",
    "        \n",
    "        else:\n",
    "            self.G.nodes[category]['visited'] = True\n",
    "            self.visited_nodes += 1\n",
    "            logging.debug(str(self.visited_nodes) + ' - Searching for ' + category +\n",
    "                          ' (depth ' + str(self.G.nodes[category]['depth']) + '), with parents ' +\n",
    "                          str(list(self.G.neighbors(category))) + '...')\n",
    "\n",
    "            if(how == 'all'):\n",
    "                for parent in self.G.neighbors(category):\n",
    "                    self.G.nodes[category]['labels'].update(self.get_label(parent, how))\n",
    "                return self.G.nodes[category]['labels']\n",
    "\n",
    "            elif(how=='naive'):\n",
    "                # non-connected categories\n",
    "                if('depth' not in self.G.nodes[category]):\n",
    "                    return set()\n",
    "    \n",
    "                depth = self.G.nodes[category]['depth']\n",
    "                for parent in self.G.neighbors(category):\n",
    "                    try:\n",
    "                        if(self.G.nodes[parent]['depth'] < depth):\n",
    "                            self.G.nodes[category]['labels'].update(self.get_label(parent, how))\n",
    "                    # Not connected category (temp fix to template expansion)\n",
    "                    except KeyError:\n",
    "                        continue\n",
    "                return self.G.nodes[category]['labels']\n",
    "\n",
    "            elif(how=='heuristics'):\n",
    "\n",
    "                # 0 Temporary solution to non-connected categories (due to missing template expansion)\n",
    "                if('depth' not in self.G.nodes[category]):\n",
    "                    logging.exception('Non connected category, returning empty set')\n",
    "                    return set()\n",
    "\n",
    "                # 1 Hidden category\n",
    "                if(self.G.nodes[category]['hiddencat']):\n",
    "                    logging.debug('Hidden category, returning empty set')\n",
    "                    return set()\n",
    "\n",
    "                # 2 Lexical head\n",
    "\n",
    "                # 2.1. Check for meaningless head (time-related + Commons-related)\n",
    "                null_heads = ['January', 'February', 'March', 'April', 'May', 'June',\n",
    "                              'July', 'August', 'September', 'October', 'November', 'December',\n",
    "                              'Spring', 'Summer', 'Autumn', 'Winter', 'Century', 'Categories', 'Category']\n",
    "                heads = [self.get_head(category)]\n",
    "                if(heads[0].isnumeric() or heads[0] in null_heads):\n",
    "                    logging.debug('Head ' + heads[0] + ' not meaningful, returning empty set')\n",
    "                    return set()\n",
    "\n",
    "                # Get heads of all parents\n",
    "                for parent in self.G.neighbors(category):\n",
    "                    heads.append(self.get_head(parent))\n",
    "                logging.debug('Heads: ' + str(heads))\n",
    "\n",
    "                # 2.2. Try to match over complete lexical heads or subsets\n",
    "                while(1):\n",
    "                    common_heads = list(unique_everseen(duplicates(heads)))\n",
    "\n",
    "                    # Break if found a common head or all the heads are already 1 word long\n",
    "                    if(common_heads or (cmax:=max(map(lambda x: len(x.split()), heads))) == 1):\n",
    "                        break\n",
    "\n",
    "                    # Remove 1 word from the longest composite heads\n",
    "                    for i, head in enumerate(heads):\n",
    "                        head_words = head.split()\n",
    "                        if(len(head_words) == cmax):\n",
    "                            heads[i] = ' '.join(head_words[1:]).capitalize()\n",
    "                    logging.debug('Lexical heads: ' + str(heads))\n",
    "                logging.debug('\\tFound common heads: ' + str(common_heads))\n",
    "\n",
    "                # 2.3. Hop to common_heads if they belong to parents and are not meaningless\n",
    "                for common_head in common_heads:\n",
    "                    if(common_head in nx.descendants(self.G, category) and \n",
    "                       not (common_head.isnumeric() or common_head in null_heads)):\n",
    "                        self.G.nodes[category]['labels'].update(self.get_label(common_head, how))\n",
    "                    else:\n",
    "                        logging.debug('Common head ' + str(common_head) + ' not found or time-related')\n",
    "                \n",
    "                # Will be empty if no common_head is found, if the common_heads are\n",
    "                # all not valid category names, hidden categories or already visited \n",
    "                # (including the current category)\n",
    "                if(self.G.nodes[category]['labels']):\n",
    "                    return self.G.nodes[category]['labels']\n",
    "\n",
    "                # 3. is_a or subcategory_of (temp: depth check)\n",
    "                depth = self.G.nodes[category]['depth']\n",
    "                for parent in self.G.neighbors(category):\n",
    "                    try:\n",
    "                        if(self.G.nodes[parent]['depth'] < depth):\n",
    "                            self.G.nodes[category]['labels'].update(self.get_label(parent, how))\n",
    "                        else:\n",
    "                            logging.debug('[' + category + '] Skipping parent ' + parent + \n",
    "                            ' (depth ' + str(self.G.nodes[parent]['depth']) + ')')\n",
    "                    # Not connected category (temp fix to template expansion)\n",
    "                    except KeyError:\n",
    "                        logging.exception('[' + category + '] Parent ' + parent + ' not connected.')\n",
    "                        continue\n",
    "                return self.G.nodes[category]['labels']\n",
    "\n",
    "            else:\n",
    "                raise ValueError('Invalid \"how\" option')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy = Taxonomy()\n",
    "taxonomy.load_categories(CATEGORIES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy = Taxonomy(taxonomy.G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy.set_taxonomy(mapping='content_extended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Entertainment'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxonomy.get_label('Comedy films of the United States')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Nature'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxonomy.get_label('Balconies in Sicily')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Events'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxonomy.get_label('2011 Ukrainian Superleague All-Star game')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxonomy.get_label('11th-century bookbinding')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "04bf3c03e93e0e94a1d038aa36107c2a70cb015ab0da2208309d202be833925b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('francesco': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
